"""
combined_analysis.py

åŠŸèƒ½:
1. è¯»å–åŸå§‹ Polaris JSON æ–‡ä»¶ï¼Œç»Ÿè®¡æ¯ä¸ªé—®é¢˜ (ID) çš„æ€»æ¡ä»¶æ•° (å³ len(removal_variants))ã€‚
2. è¯»å–ç­›é€‰åçš„ JSON æ–‡ä»¶ï¼Œç»Ÿè®¡æ¯ä¸ªåŸå§‹é—®é¢˜ (original_id) å‰©ä¸‹çš„å˜ä½“æ•°é‡ã€‚
3. ç»“åˆä¸¤é¡¹ç»Ÿè®¡ç»“æœï¼Œè®¡ç®—ä¿ç•™ç‡ï¼Œå¹¶è¾“å‡ºä¸º Markdown è¡¨æ ¼ã€‚
"""

import json
import os
from collections import defaultdict
import argparse
import sys

def load_data(file_path: str) -> list:
    """åŠ è½½ JSON æ–‡ä»¶ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦ä¸ºåˆ—è¡¨ã€‚"""
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if not isinstance(data, list):
                # å‡è®¾å•ä¸ªå¯¹è±¡ä¹Ÿæœ‰æ•ˆï¼Œå°†å…¶åŒ…è£…æˆåˆ—è¡¨
                return [data]
            return data
    except json.JSONDecodeError as e:
        print(f"âŒ é”™è¯¯ï¼šJSON æ–‡ä»¶è§£ç å¤±è´¥ ({file_path}): {e}")
        return []
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šè¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ ({file_path}): {e}")
        return []

def get_original_counts(data: list) -> dict:
    """
    ä»åŸå§‹æ•°æ®ä¸­ç»Ÿè®¡æ¯ä¸ª ID çš„æ€»æ¡ä»¶æ•°ã€‚
    æ€»æ¡ä»¶æ•° = len(item['removal_variants'])
    """
    counts = {}
    for item in data:
        problem_id = item.get("id")
        # ç¡®ä¿ ID æ˜¯å¯å“ˆå¸Œçš„ä¸”æœ‰æ•ˆ
        if problem_id is not None:
            variants = item.get("removal_variants", [])
            counts[problem_id] = len(variants)
    return counts

def get_filtered_counts(data: list) -> defaultdict:
    """
    ä»ç­›é€‰æ•°æ®ä¸­ç»Ÿè®¡æ¯ä¸ª original_id å‰©ä¸‹çš„å˜ä½“æ•°é‡ã€‚
    """
    counts = defaultdict(int)
    for item in data:
        original_id = item.get("original_id")
        if original_id is not None:
            counts[original_id] += 1
    return counts

def run_analysis(original_file: str, filtered_file: str):
    """æ‰§è¡Œå®Œæ•´çš„åˆ†æå¹¶è¾“å‡ºè¡¨æ ¼ç»“æœã€‚"""
    print(f"æ­£åœ¨åŠ è½½åŸå§‹æ•°æ®: {original_file}...")
    original_data = load_data(original_file)
    original_counts = get_original_counts(original_data)
    
    print(f"æ­£åœ¨åŠ è½½ç­›é€‰æ•°æ®: {filtered_file}...")
    filtered_data = load_data(filtered_file)
    filtered_counts = get_filtered_counts(filtered_data)
    
    if not original_counts and not filtered_counts:
        print("æ— æœ‰æ•ˆæ•°æ®å¯ä¾›åˆ†æã€‚è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
        return

    # --- ç»„åˆæ•°æ®å¹¶å‡†å¤‡è¾“å‡º ---
    
    # è·å–æ‰€æœ‰æ¶‰åŠçš„ ID
    all_ids = set(original_counts.keys()) | set(filtered_counts.keys())
    
    results = []
    total_original = 0
    total_filtered = 0
    
    # è½¬æ¢ä¸ºæ•´æ•°åæ’åº
    sorted_ids = sorted(list(all_ids), key=lambda x: int(x) if str(x).isdigit() else sys.maxsize)

    for problem_id in sorted_ids:
        # è·å–æ•°é‡
        total = original_counts.get(problem_id, 0)
        filtered = filtered_counts.get(problem_id, 0)
        
        # è®¡ç®—ä¿ç•™ç‡
        retention_rate = (filtered / total) * 100 if total > 0 else 0.0
        
        # å¤‡æ³¨é€»è¾‘
        notes = ""
        if total == 0 and filtered > 0:
             notes = "åŸå§‹è®°å½•ç¼ºå¤±ï¼Œä½†ç­›é€‰æ•°æ®ä¸­æœ‰ä¿ç•™é¡¹ã€‚"
        elif filtered == 0 and total > 0:
            notes = "æ‰€æœ‰å˜ä½“å‡è¢«ç­›é€‰æ‰ã€‚"
        elif total != filtered and filtered > 0 and total > 0:
            notes = f"æœ‰ {total - filtered} ä¸ªå˜ä½“è¢«ç­›é€‰æ‰ã€‚"
        elif total == filtered and total > 0:
             notes = "æ‰€æœ‰å˜ä½“å‡ä¿ç•™ã€‚"
        
        results.append({
            "id": problem_id,
            "total_conditions": total,
            "filtered_count": filtered,
            "retention_rate": f"{retention_rate:.1f}%",
            "notes": notes
        })
        
        total_original += total
        total_filtered += filtered

    # --- è¾“å‡º Markdown è¡¨æ ¼ (å³å¯è§†åŒ–ç»“æœ) ---
    
    print("\n" + "=" * 50)
    print("## ğŸ“Š Polaris æ¡ä»¶ç§»é™¤å˜ä½“ç»Ÿè®¡ç»“æœ")
    print("-" * 50)
    
    # è¡¨æ ¼å¤´éƒ¨
    print("| Original ID | åŸå§‹æ€»æ¡ä»¶æ•° | ç­›é€‰åä¿ç•™å˜ä½“æ•° | ä¿ç•™ç‡ | å¤‡æ³¨ |")
    print("|:---:|:---:|:---:|:---:|:---|")
    
    # è¡¨æ ¼å†…å®¹
    for row in results:
        print(f"| {row['id']} | **{row['total_conditions']}** | **{row['filtered_count']}** | {row['retention_rate']} | {row['notes']} |")

    # æ€»è®¡è¡Œ
    overall_retention = (total_filtered / total_original) * 100 if total_original > 0 else 0.0
    print("-" * 50)
    print(f"| **æ€»è®¡** | **{total_original}** | **{total_filtered}** | **{overall_retention:.1f}%** | |")
    print("=" * 50)
    
    print("\n**é‡è¦è¯´æ˜:**")
    print("1. **åŸå§‹æ€»æ¡ä»¶æ•°**ï¼šæ ¹æ® `len(removal_variants)` å­—æ®µè®¡ç®—ã€‚")
    print("2. **ç­›é€‰åä¿ç•™å˜ä½“æ•°**ï¼šæ ¹æ®ç­›é€‰æ–‡ä»¶ä¸­çš„ `original_id` è®¡æ•°ã€‚")
    print("3. å¦‚æœæŸ ID çš„'åŸå§‹æ€»æ¡ä»¶æ•°'ä¸º 0 ä½†'ç­›é€‰åä¿ç•™å˜ä½“æ•°'å¤§äº 0ï¼Œè¯´æ˜åŸå§‹ JSON ä¸­è¯¥é—®é¢˜æ²¡æœ‰ `removal_variants` å­—æ®µæˆ–å…¶å€¼ä¸ºç©ºï¼Œä½†æ‚¨çš„ç­›é€‰ç»“æœä¸­åŒ…å«äº†è¯¥ ID çš„å˜ä½“ã€‚**è¿™å¯èƒ½æ˜¯åŸå§‹æ•°æ®ä¸å®Œæ•´æˆ–æ•°æ®æ ¼å¼ä¸ä¸€è‡´å¯¼è‡´çš„ã€‚**")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="åˆ†æ Polaris æ¡ä»¶ç§»é™¤å˜ä½“æ•°æ®ï¼Œè®¡ç®—æ¯ä¸ªé—®é¢˜çš„æ€»æ¡ä»¶æ•°å’Œç­›é€‰åä¿ç•™æ•°ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--original_file", 
        type=str, 
        help="åŸå§‹ Polaris JSON æ–‡ä»¶è·¯å¾„ (åŒ…å« 'removal_variants' å­—æ®µ)"
    )
    parser.add_argument(
        "--filtered_file", 
        type=str, 
        help="ç­›é€‰åçš„ JSON æ–‡ä»¶è·¯å¾„ (åŒ…å« 'original_id' å­—æ®µ)"
    )
    
    args = parser.parse_args()
    
    run_analysis(args.original_file, args.filtered_file)